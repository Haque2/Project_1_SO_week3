{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b28b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a81fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://fred.stlouisfed.org/release/tables?rid=110&eid=257197&od=2022-01-01#\"\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "average_income = soup.find_all('td', \"fred-rls-elm-vl-td\")[::3]\n",
    "average_income_lists = [i.get_text().strip() for i in average_income]\n",
    "average_income_lists\n",
    "name_state = soup.find_all('span', class_=\"fred-rls-elm-nm\")\n",
    "name_state_lists = [i.get_text() for i in name_state]\n",
    "name_state_lists\n",
    "states = [i for i in name_state_lists]\n",
    "incomes= [i for i in average_income_lists]\n",
    "income_state_df = pd.DataFrame({'State': states,'Av_income': incomes,}).sort_values('State').reset_index(drop= True )\n",
    "income_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfffd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://worldpopulationreview.com/states\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "type(soup)\n",
    "soup.find(\"title\")\n",
    "print(response.status_code)\n",
    "\n",
    "name_state = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[::8]\n",
    "name_state_lists = [i.get_text().strip() for i in name_state][:50:]\n",
    "last_city = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[407:412:]\n",
    "last_city_lists = [i.get_text().strip() for i in last_city][0]\n",
    "name_state_lists.append(last_city_lists)\n",
    "population = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[3::8]\n",
    "population_lists = [i.get_text().strip() for i in population][:50:]\n",
    "last_population = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[407:412:]\n",
    "last_population_lists = [i.get_text().strip() for i in last_city][3]\n",
    "population_lists.append(last_population_lists)\n",
    "\n",
    "name_state1 = []\n",
    "population = []\n",
    "states1 = [i for i in name_state_lists]\n",
    "population = [i for i in population_lists]\n",
    "population_df = pd.DataFrame({'State': states, 'Population': population}).sort_values('State').reset_index(drop= True )\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf32f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing a database from  kaggle\n",
    "import pandas as pd\n",
    "\n",
    "dfdb = pd.read_csv(r\"C:\\Users\\38095\\Documents\\GitHub\\Project_1_SO_week3\\linkedin-jobs-usa.csv\")\n",
    "# fixing the salary column take off the simbols ect..\n",
    "salary_values = dfdb['salary'].str.split('-', expand=True)\n",
    "lower_salary = salary_values[0].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "upper_salary = salary_values[1].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "#finding the average of this two numbers\n",
    "average = (upper_salary + lower_salary)/2\n",
    "dfdb['salary'] = average.round()\n",
    "dfdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repacing values in salary column becsuse there are to many mistakes\n",
    "dict_salary ={55.0 : 55000,\n",
    "              70.0 : 70000,\n",
    "              50.0 : 50000,\n",
    "              32.0 : 32000,\n",
    "              60.0 : 60000,\n",
    "              30.0 : 30000,\n",
    "              23.0 : 45000,\n",
    "              45.0 : 45000,\n",
    "              42.0 : 42000,\n",
    "              5900.0 : 59000,\n",
    "              29.0 : 29000,\n",
    "              35.0 : 35000,\n",
    "              36.0 :36000,\n",
    "              40.0 :40000,\n",
    "              69.0 :69000\n",
    "              }\n",
    "dfdb.salary = dfdb.salary.replace(dict_salary)\n",
    "\n",
    "dfdb.salary.mean()\n",
    "# filling some null values\n",
    "\n",
    "dfdb.title.fillna(\"Junior Data Analyst\", inplace = True)\n",
    "\n",
    "dfdb.isnull().any()\n",
    "\n",
    "dfdb.title.value_counts()\n",
    "# fixing the job titles\n",
    "\n",
    "title_mapping = {\n",
    "    \"Data Visualization\": \"Data Visualization\",\n",
    "    \"Junior\": \"Junior Data Analyst\",\n",
    "    \"Data and Analytics\": \"Data and Analytics\",\n",
    "    \"Associate Data Analyst\": \"Associate Data Analyst\",\n",
    "    \"Business Data Analyst\": \"Business Data Analyst\",\n",
    "    \"Consultant\": \"Consultant\",\n",
    "    \"Global Remote\": \"Remote Data Analyst\",\n",
    "    \"Hybrid\": \"Hybrid Data Analyst\",\n",
    "    \"Remote\": \"Remote Data Analyst\",\n",
    "    \"SQL\": \"SQL Data Analyst\",\n",
    "    \"Energy\": \"Energy Data Analyst\",\n",
    "    \"Recent Graduate\": \"Recent Graduate Data Analyst\",\n",
    "    \"Weekly Hybrid Remote/Onsite Schedule\": \"Hybrid Data Analyst\",\n",
    "    \"Collector\": \"Collector Data Analyst\",\n",
    "    \"Data Analytics\": \"Data Analytics Analyst\",\n",
    "    \"Marketing\": \"Marketing Data Analyst\",\n",
    "    \"SQL, Operations\": \"SQL Data Analyst\",\n",
    "    \"Senior\": \"Senior Data Analyst\",\n",
    "    \"Entry Level\": \"Entry Level Data Analyst\",\n",
    "    \"Data Analyst\": \"Data Analyst\"\n",
    "}\n",
    "\n",
    "\n",
    "def map_job_title(title):\n",
    "    for key, value in title_mapping.items():\n",
    "        if key.lower() in title.lower():\n",
    "            return value\n",
    "    return title\n",
    "\n",
    "\n",
    "updated_title = dfdb[\"title\"].apply(map_job_title)\n",
    "dfdb[\"title\"] = updated_title\n",
    "#finding the average  salary for each title of job\n",
    "average_salary_by_title = dfdb.groupby(\"title\")['salary'].mean()\n",
    "#fixing satetes because some of them have just the prefixes\n",
    "state_mapping_full = {\n",
    "    \"United States\": \"United States\",\n",
    "    \"New York City Metropolitan Area\": \"New York\",\n",
    "    \"Chicago, IL\": \"Illinois\",\n",
    "    \"New York, NY\": \"New York\",\n",
    "    \"Austin, TX\": \"Texas\",\n",
    "    \"Texas, United States\": \"Texas\",\n",
    "    \"Timonium, MD\": \"Maryland\",\n",
    "    \"Dallas, TX\": \"Texas\",\n",
    "    \"Boston, MA\": \"Massachusetts\",\n",
    "    \"Charlotte, NC\": \"North Carolina\",\n",
    "    \"Miami, FL\": \"Florida\",\n",
    "    \"New York, United States\": \"New York\",\n",
    "    \"Franklin, TN\": \"Tennessee\",\n",
    "    \"Tempe, AZ\": \"Arizona\",\n",
    "    \"Illinois, United States\": \"Illinois\",\n",
    "    \"Greensboro--Winston-Salem--High Point Area\": \"North Carolina\",\n",
    "    \"Greater Scranton Area\": \"Pennsylvania\",\n",
    "    \"Tennessee, United States\": \"Tennessee\",\n",
    "    \"Indiana, United States\": \"Indiana\",\n",
    "    \"Denver Metropolitan Area\": \"Colorado\",\n",
    "    \"District of Columbia, United States\": \"District of Columbia\",\n",
    "    \"Conshohocken, PA\": \"Pennsylvania\",\n",
    "    \"Phoenix, AZ\": \"Arizona\",\n",
    "    \"North Carolina, United States\": \"North Carolina\",\n",
    "    \"Greater Sacramento\": \"California\",\n",
    "    \"Richfield, MN\": \"Minnesota\",\n",
    "    \"Morgan Hill, CA\": \"California\",\n",
    "    \"Cincinnati Metropolitan Area\": \"Ohio\",\n",
    "    \"Hartford, CT\": \"Connecticut\",\n",
    "    \"Atlanta Metropolitan Area\": \"Georgia\",\n",
    "    \"Quincy, MA\": \"Massachusetts\",\n",
    "    \"Buffalo-Niagara Falls Area\": \"New York\",\n",
    "    \"San Francisco, CA\": \"California\",\n",
    "    \"Irvine, CA\": \"California\",\n",
    "    \"Houston, TX\": \"Texas\",\n",
    "    \"Omaha, NE\": \"Nebraska\",\n",
    "    \"San Jose, CA\": \"California\",\n",
    "    \"Scottsdale, AZ\": \"Arizona\",\n",
    "    \"San Francisco Bay Area\": \"California\",\n",
    "    \"Manassas, VA\": \"Virginia\"\n",
    "}\n",
    "\n",
    "\n",
    "dfdb['location'] = dfdb['location'].map(state_mapping_full)\n",
    "# replacing the result for the usa in other values\n",
    "state_counts = dfdb[\"location\"].value_counts()\n",
    "total_count = state_counts.sum() - state_counts[\"United States\"]\n",
    "ratios = state_counts / total_count\n",
    "replacements = (dfdb[\"location\"].value_counts()[\"United States\"] * ratios).round().astype(int)\n",
    "print(replacements)\n",
    "for i, location in enumerate(dfdb[\"location\"]):\n",
    "    if location == \"United States\":\n",
    "        for key, value in replacements.items():\n",
    "            if value > 0 and key != \"United States\":\n",
    "                dfdb.at[i, \"location\"] = key\n",
    "                replacements[key] -= 1\n",
    "                break\n",
    "\n",
    "\n",
    "dfdb.groupby(\"location\")[\"salary\"].mean()\n",
    "\n",
    "data = {\n",
    "    \"State\": [\"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\",\n",
    "                 \"Florida\", \"Georgia\", \"Illinois\", \"Indiana\", \"Maryland\", \"Massachusetts\",\n",
    "                 \"Minnesota\", \"Nebraska\", \"New York\", \"North Carolina\", \"Ohio\", \n",
    "                 \"Pennsylvania\", \"Tennessee\", \"Texas\"],\n",
    "    \"Av_salary\": [81431.818182, 70408.450704, 40411.111111, 89375.000000, 117546.511628,\n",
    "               86250.000000, 81888.888889, 86000.000000, 103750.000000, 86363.636364,\n",
    "               82700.000000, 50583.333333, 95000.000000, 72483.673469, 69901.639344,\n",
    "               71000.000000, 86603.829787, 102305.555556, 83276.595745],\n",
    "    \"Number_of_Vac\": [135, 251, 49, 47, 49, 54, 46, 258, 50, 82, 119, 47, 41, 475, 153, 47, 97, 101, 302]\n",
    "}\n",
    "# thats the dataframe  that groups the columns that we want to compare\n",
    "result_df = pd.DataFrame(data)\n",
    "df_by_title = dfdb.groupby([\"location\", \"title\"]).agg({\"salary\": \"mean\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "merged_df = pd.merge(population_df, income_state_df, on='State', how='left')\n",
    "merged_df = pd.merge(merged_df, result_df, on='State', how='left')\n",
    "merged_df['Population'] = merged_df['Population'].str.replace(',', '').astype(int)\n",
    "merged_df['Population'] = (merged_df['Population']/1000000).round(2)\n",
    "\n",
    "\n",
    "merged_df['Av_income'] = merged_df['Av_income'].str.replace(',', '').astype(int)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24711414",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "merged_df.dropna(how='any', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reset_index(drop= True )\n",
    "merged_df.dropna(how='any', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Vacancies/Population'] = merged_df['Number_of_Vac']/merged_df['Population']\n",
    "merged_df['Av_salary/Av_income'] = (merged_df['Av_salary']/merged_df['Av_income'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51261fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Vacancies/Population'] = merged_df['Vacancies/Population'].astype(float)\n",
    "merged_df['Vacancies/Population'] = merged_df['Vacancies/Population'].map(lambda x: round(x, 6))\n",
    "merged_df['Av_salary/Av_income'] = merged_df['Av_salary/Av_income'].map(\"{:.2f}%\".format)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b312b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this barchart shows the comparing the average income per state and average salary of working in data analysis whatever is the field\n",
    "sorted_df = merged_df.sort_values(by='Av_income')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_df['State'], sorted_df['Av_income'], color='skyblue')\n",
    "plt.title('Per Capita Personal Income by State, Annual')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Income')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b47a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.35\n",
    "index = range(len(merged_df))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(index, merged_df['Av_income'], bar_width, label='PCP Income')\n",
    "plt.bar([i + bar_width for i in index], merged_df['Av_salary'], bar_width, label='Average Salary for DA')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Average Salary for DA and Per Capita Personal Income by State')\n",
    "plt.xticks([i + bar_width/2 for i in index], merged_df['State'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.savefig('Average Salary for DA and Per Capita Personal Income by State')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "##############################################################\n",
    "bar_width = 0.35\n",
    "index = range(len(merged_df))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(index, merged_df['Population'], bar_width, label='Population in mln.')\n",
    "plt.bar([i + bar_width for i in index], merged_df['Number_of_Vac'], bar_width, label='Number of Vacancies per 1 million')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Population and number of DA Vacancies')\n",
    "plt.xticks([i + bar_width/2 for i in index], merged_df['State'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.savefig('Population and number of DA Vacancies')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd69b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Av_income_sort_df = merged_df.sort_values(by='Av_income')\n",
    "Vac_pop_sort_df = merged_df.sort_values(by='Vacancies/Population')\n",
    "Sal_income_sort_df = merged_df.sort_values(by='Av_salary/Av_income')\n",
    "Av_income_sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vac_pop_sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sal_income_sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1_subset  = Av_income_sort_df.head(5)\n",
    "set2_subset  = Vac_pop_sort_df.head(5)\n",
    "set3_subset  = Sal_income_sort_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_come_df = pd.DataFrame()\n",
    "out_come_df = pd.concat([set1_subset , set2_subset , set3_subset], ignore_index=True)\n",
    "out_come_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = out_come_df['State'].value_counts()\n",
    "state_rating_dict = state_counts.to_dict()\n",
    "state_rating_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81612f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_states = list(state_rating_dict.keys())[:5]\n",
    "best_choice_df = merged_df[merged_df['State'].isin(top_five_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e20ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = best_choice_df.sort_values(by=['Vacancies/Population', 'Av_salary/Av_income', 'Av_salary'], ascending=[False, False, False]).reset_index(drop= True )\n",
    "last_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd20cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df['Population'] = last_df['Population']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e32fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = range(len(last_df))\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax1.bar(index, last_df['Vacancies/Population'], bar_width, label='Number of Vacancies per 1 million', color='b')\n",
    "ax1.set_xlabel('State')\n",
    "ax1.set_ylabel('Number of Vacancies per 1 million', color='b')\n",
    "ax1.set_title('The best states for DA')\n",
    "ax1.set_xticks(index)\n",
    "ax1.set_xticklabels(last_df['State'], rotation=90)\n",
    "ax1.legend(loc='upper left')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(index, last_df['Av_salary/Av_income'], color='r', marker='o', label='Av_salary/Av_income')\n",
    "ax2.set_ylabel('Average Salary / Average Income', color='r')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.savefig('The_best_states_for_DA.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_df = merged_df[[\"State\",\"Av_income\"]]\n",
    "\n",
    "ai_df = ai_df.rename(columns={\"State\":\"location\",\"Av_income\":\"salary\"})\n",
    "\n",
    "title_and_avg = pd.concat([ai_df,df_by_title])\n",
    "\n",
    "title_avg = title_and_avg.sort_values(\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this barchart compares average income for each state with average salary for every type of job in data analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 9))\n",
    "bar_width = 0.4 \n",
    "sns.barplot(data=title_avg, x='location', y='salary', hue='title', dodge=False, width=bar_width)\n",
    "ax = plt.gca()\n",
    "sns.barplot(data=merged_df, x='State', y='Av_income', saturation=0.75, alpha=0.3, color='yellow', label='Average Income', ci=None, ax=ax)\n",
    "plt.title('Salary by Position and Location')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Salary')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6df6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
