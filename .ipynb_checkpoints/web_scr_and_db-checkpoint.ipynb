{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b28b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\38095\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\38095\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\38095\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\38095\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\38095\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\38095\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\38095\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a81fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Av_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>50,920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>68,664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>58,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>52,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>77,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>75,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>83,340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>63,177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>96,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>64,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>56,588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>61,813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>56,615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>67,653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>58,329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>60,238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>60,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>51,929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>54,527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>60,425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>70,236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>84,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>57,043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>68,874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>46,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>57,825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>60,984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>64,263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>62,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>73,711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>77,206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>52,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York</td>\n",
       "      <td>75,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>58,125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>70,391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>57,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>56,306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>62,314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>64,506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>63,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>53,615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>68,173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>58,311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>62,585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>59,449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>63,035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>69,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>75,345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>50,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>61,496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>73,216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State Av_income\n",
       "0                Alabama    50,920\n",
       "1                 Alaska    68,664\n",
       "2                Arizona    58,390\n",
       "3               Arkansas    52,604\n",
       "4             California    77,013\n",
       "5               Colorado    75,708\n",
       "6            Connecticut    83,340\n",
       "7               Delaware    63,177\n",
       "8   District of Columbia    96,092\n",
       "9                Florida    64,804\n",
       "10               Georgia    56,588\n",
       "11                Hawaii    61,813\n",
       "12                 Idaho    56,615\n",
       "13              Illinois    67,653\n",
       "14               Indiana    58,329\n",
       "15                  Iowa    60,238\n",
       "16                Kansas    60,433\n",
       "17              Kentucky    51,929\n",
       "18             Louisiana    54,527\n",
       "19                 Maine    60,425\n",
       "20              Maryland    70,236\n",
       "21         Massachusetts    84,551\n",
       "22              Michigan    57,043\n",
       "23             Minnesota    68,874\n",
       "24           Mississippi    46,388\n",
       "25              Missouri    57,825\n",
       "26               Montana    60,984\n",
       "27              Nebraska    64,263\n",
       "28                Nevada    62,092\n",
       "29         New Hampshire    73,711\n",
       "30            New Jersey    77,206\n",
       "31            New Mexico    52,190\n",
       "32              New York    75,423\n",
       "33        North Carolina    58,125\n",
       "34          North Dakota    70,391\n",
       "35                  Ohio    57,759\n",
       "36              Oklahoma    56,306\n",
       "37                Oregon    62,314\n",
       "38          Pennsylvania    64,506\n",
       "39          Rhode Island    63,551\n",
       "40        South Carolina    53,615\n",
       "41          South Dakota    68,173\n",
       "42             Tennessee    58,311\n",
       "43                 Texas    62,585\n",
       "44                  Utah    59,449\n",
       "45               Vermont    63,035\n",
       "46              Virginia    69,021\n",
       "47            Washington    75,345\n",
       "48         West Virginia    50,024\n",
       "49             Wisconsin    61,496\n",
       "50               Wyoming    73,216"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://fred.stlouisfed.org/release/tables?rid=110&eid=257197&od=2022-01-01#\"\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "average_income = soup.find_all('td', \"fred-rls-elm-vl-td\")[::3]\n",
    "average_income_lists = [i.get_text().strip() for i in average_income]\n",
    "average_income_lists\n",
    "name_state = soup.find_all('span', class_=\"fred-rls-elm-nm\")\n",
    "name_state_lists = [i.get_text() for i in name_state]\n",
    "name_state_lists\n",
    "states = [i for i in name_state_lists]\n",
    "incomes= [i for i in average_income_lists]\n",
    "income_state_df = pd.DataFrame({'State': states,'Av_income': incomes,}).sort_values('State').reset_index(drop= True )\n",
    "income_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfffd6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>38,965,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>30,503,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>22,610,726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>19,571,216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>12,961,683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>12,549,689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>11,785,935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>11,029,227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>10,835,491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>10,037,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>9,290,841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>8,715,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>7,812,880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>7,431,344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>7,126,489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>7,001,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>6,862,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>6,196,156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>6,180,253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>5,910,955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>5,877,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>5,737,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>5,373,555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>5,108,468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>4,573,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>4,526,154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>4,233,358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>4,053,824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>3,617,176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>3,417,734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>3,207,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>3,194,176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York</td>\n",
       "      <td>3,067,732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2,940,546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2,939,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2,114,371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1,964,726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>1,978,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1,770,071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1,435,138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1,402,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>1,395,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1,132,812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1,095,962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1,031,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>919,318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>783,926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>733,406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>647,464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>584,057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>678,972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State  Population\n",
       "0                Alabama  38,965,193\n",
       "1                 Alaska  30,503,301\n",
       "2                Arizona  22,610,726\n",
       "3               Arkansas  19,571,216\n",
       "4             California  12,961,683\n",
       "5               Colorado  12,549,689\n",
       "6            Connecticut  11,785,935\n",
       "7               Delaware  11,029,227\n",
       "8   District of Columbia  10,835,491\n",
       "9                Florida  10,037,261\n",
       "10               Georgia   9,290,841\n",
       "11                Hawaii   8,715,698\n",
       "12                 Idaho   7,812,880\n",
       "13              Illinois   7,431,344\n",
       "14               Indiana   7,126,489\n",
       "15                  Iowa   7,001,399\n",
       "16                Kansas   6,862,199\n",
       "17              Kentucky   6,196,156\n",
       "18             Louisiana   6,180,253\n",
       "19                 Maine   5,910,955\n",
       "20              Maryland   5,877,610\n",
       "21         Massachusetts   5,737,915\n",
       "22              Michigan   5,373,555\n",
       "23             Minnesota   5,108,468\n",
       "24           Mississippi   4,573,749\n",
       "25              Missouri   4,526,154\n",
       "26               Montana   4,233,358\n",
       "27              Nebraska   4,053,824\n",
       "28                Nevada   3,617,176\n",
       "29         New Hampshire   3,417,734\n",
       "30            New Jersey   3,207,004\n",
       "31            New Mexico   3,194,176\n",
       "32              New York   3,067,732\n",
       "33        North Carolina   2,940,546\n",
       "34          North Dakota   2,939,690\n",
       "35                  Ohio   2,114,371\n",
       "36              Oklahoma   1,964,726\n",
       "37                Oregon   1,978,379\n",
       "38          Pennsylvania   1,770,071\n",
       "39          Rhode Island   1,435,138\n",
       "40        South Carolina   1,402,054\n",
       "41          South Dakota   1,395,722\n",
       "42             Tennessee   1,132,812\n",
       "43                 Texas   1,095,962\n",
       "44                  Utah   1,031,890\n",
       "45               Vermont     919,318\n",
       "46              Virginia     783,926\n",
       "47            Washington     733,406\n",
       "48         West Virginia     647,464\n",
       "49             Wisconsin     584,057\n",
       "50               Wyoming     678,972"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://worldpopulationreview.com/states\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "type(soup)\n",
    "soup.find(\"title\")\n",
    "print(response.status_code)\n",
    "\n",
    "name_state = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[::8]\n",
    "name_state_lists = [i.get_text().strip() for i in name_state][:50:]\n",
    "last_city = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[407:412:]\n",
    "last_city_lists = [i.get_text().strip() for i in last_city][0]\n",
    "name_state_lists.append(last_city_lists)\n",
    "population = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[3::8]\n",
    "population_lists = [i.get_text().strip() for i in population][:50:]\n",
    "last_population = soup.find_all(\"td\", class_=\"z-40 border px-2 py-0.5\")[407:412:]\n",
    "last_population_lists = [i.get_text().strip() for i in last_city][3]\n",
    "population_lists.append(last_population_lists)\n",
    "\n",
    "name_state1 = []\n",
    "population = []\n",
    "states1 = [i for i in name_state_lists]\n",
    "population = [i for i in population_lists]\n",
    "population_df = pd.DataFrame({'State': states, 'Population': population}).sort_values('State').reset_index(drop= True )\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d03725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf32f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c225164a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "United States           221\n",
      "New York                123\n",
      "Texas                    78\n",
      "Illinois                 67\n",
      "California               65\n",
      "North Carolina           40\n",
      "Arizona                  35\n",
      "Massachusetts            31\n",
      "Tennessee                26\n",
      "Pennsylvania             25\n",
      "Maryland                 21\n",
      "Florida                  14\n",
      "Indiana                  13\n",
      "Colorado                 13\n",
      "District of Columbia     13\n",
      "Ohio                     12\n",
      "Minnesota                12\n",
      "Connecticut              12\n",
      "Georgia                  12\n",
      "Nebraska                 11\n",
      "Virginia                  9\n",
      "Name: count, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfdb = pd.read_csv(r\"C:\\Users\\38095\\Documents\\GitHub\\Project1-copies\\linkedin-jobs-usa.csv\")\n",
    "\n",
    "salary_values = dfdb['salary'].str.split('-', expand=True)\n",
    "lower_salary = salary_values[0].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "upper_salary = salary_values[1].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "average = (upper_salary + lower_salary)/2\n",
    "dfdb['salary'] = average.round()\n",
    "dfdb\n",
    "\n",
    "dict_salary ={55.0 : 55000,\n",
    "              70.0 : 70000,\n",
    "              50.0 : 50000,\n",
    "              32.0 : 32000,\n",
    "              60.0 : 60000,\n",
    "              30.0 : 30000,\n",
    "              23.0 : 45000,\n",
    "              45.0 : 45000,\n",
    "              42.0 : 42000,\n",
    "              5900.0 : 59000,\n",
    "              29.0 : 29000,\n",
    "              35.0 : 35000,\n",
    "              36.0 :36000,\n",
    "              40.0 :40000,\n",
    "              69.0 :69000\n",
    "              }\n",
    "dfdb.salary = dfdb.salary.replace(dict_salary)\n",
    "\n",
    "dfdb.salary.mean()\n",
    "\n",
    "dfdb.title.fillna(\"Junior Data Analyst\", inplace = True)\n",
    "\n",
    "dfdb.isnull().any()\n",
    "\n",
    "dfdb.title.value_counts()\n",
    "\n",
    "# Dictionary to map similar job titles to a standardized title\n",
    "#title_mapping = {\n",
    " #   \"Analyst (Global Data and Analytics)\": \"Global Data and Analytics Analyst\",\n",
    "  #  \"Analyst - Data Visualization\": \"Data Visualization Analyst\",\n",
    "  #  \"Analyst, Data and Analytics\": \"Data and Analytics Analyst\",\n",
    "   # \"Associate Data Analyst\": \"Associate Data Analyst\",\n",
    "    #\"Business Data Analyst\": \"Business Data Analyst\",\n",
    " #   \"Consultant/Data Analyst\": \"Consultant/Data Analyst\",\n",
    " #   \"Data Analyst\": \"Data Analyst\",\n",
    " #   \"Data Analyst (Global Remote)\": \"Global Remote Data Analyst\",\n",
    " #   \"Data Analyst (Hybrid)\": \"Hybrid Data Analyst\",\n",
    " #   \"Data Analyst (Remote)\": \"Remote Data Analyst\",\n",
    " #   \"Data Analyst (SQL)\": \"SQL Data Analyst\",\n",
    "   # \"Data Analyst (SQL, Teraform, Tableau) III - Remote\": \"Remote SQL Data Analyst\",\n",
    "    #\"Data Analyst - (Remote - US)\": \"Remote US Data Analyst\",\n",
    "  #  \"Data Analyst - Energy\": \"Energy Data Analyst\",\n",
    "   # \"Data Analyst - Recent Graduate\": \"Recent Graduate Data Analyst\",\n",
    "  #  \"Data Analyst - Remote\": \"Remote Data Analyst\",\n",
    "  #  \"Data Analyst - Weekly Hybrid Remote/Onsite Schedule\": \"Weekly Hybrid Remote/Onsite Data Analyst\",\n",
    "  #  \"Data Analyst - remote!\": \"Remote Data Analyst\",\n",
    "  #  \"Data Analyst I\": \"Data Analyst I\",\n",
    "  #  \"Data Analyst I (entry level)\": \"Entry Level Data Analyst\",\n",
    "  #  \"Data Analyst III - Remote\": \"Remote Data Analyst III\",\n",
    "  #  \"Data Analyst, Money\": \"Money Data Analyst\",\n",
    "  #  \"Data Analyst/ $100M Valuation/ Hybrid\": \"Hybrid Data Analyst\",\n",
    "  #  \"Data Analyst/Collector\": \"Collector Data Analyst\",\n",
    "  #  \"Data Analytics Analyst\": \"Data Analytics Analyst\",\n",
    "  #  \"Data Visualization Analyst\": \"Data Visualization Analyst\",\n",
    "  #  \"Data analyst\": \"Data Analyst\",\n",
    "  #  \"Entry Level Data Analyst\": \"Entry Level Data Analyst\",\n",
    "   # \"Entry-Level Data Analyst\": \"Entry Level Data Analyst\",\n",
    "    #\"Group Data Analyst\": \"Group Data Analyst\",\n",
    "    #\"Junior Data Analyst\": \"Junior Data Analyst\",\n",
    "  #  \"Junior Data Analyst-Entry Level\": \"Junior Data Analyst\",\n",
    "  #  \"Marketing Data Analyst\": \"Marketing Data Analyst\",\n",
    "  #  \"REMOTE Data Analyst (SQL, Operations)\": \"Remote SQL Data Analyst\",\n",
    "   # \"SQL Data Analyst\": \"SQL Data Analyst\",\n",
    "   # \"Senior Data Analyst\": \"Senior Data Analyst\"\n",
    "#}\n",
    "\n",
    "# Update DataFrame with standardized job titles\n",
    "#df2['title'] = df2['title'].map(title_mapping)\n",
    "# Dictionary to map similar job titles to a standardized title\n",
    "title_mapping = {\n",
    "    \"Data Visualization\": \"Data Visualization\",\n",
    "    \"Junior\": \"Junior Data Analyst\",\n",
    "    \"Data and Analytics\": \"Data and Analytics\",\n",
    "    \"Associate Data Analyst\": \"Associate Data Analyst\",\n",
    "    \"Business Data Analyst\": \"Business Data Analyst\",\n",
    "    \"Consultant\": \"Consultant\",\n",
    "    \"Global Remote\": \"Remote Data Analyst\",\n",
    "    \"Hybrid\": \"Hybrid Data Analyst\",\n",
    "    \"Remote\": \"Remote Data Analyst\",\n",
    "    \"SQL\": \"SQL Data Analyst\",\n",
    "    \"Energy\": \"Energy Data Analyst\",\n",
    "    \"Recent Graduate\": \"Recent Graduate Data Analyst\",\n",
    "    \"Weekly Hybrid Remote/Onsite Schedule\": \"Hybrid Data Analyst\",\n",
    "    \"Collector\": \"Collector Data Analyst\",\n",
    "    \"Data Analytics\": \"Data Analytics Analyst\",\n",
    "    \"Marketing\": \"Marketing Data Analyst\",\n",
    "    \"SQL, Operations\": \"SQL Data Analyst\",\n",
    "    \"Senior\": \"Senior Data Analyst\",\n",
    "    \"Entry Level\": \"Entry Level Data Analyst\",\n",
    "    \"Data Analyst\": \"Data Analyst\"\n",
    "}\n",
    "\n",
    "# Update DataFrame with standardized job titles\n",
    "def map_job_title(title):\n",
    "    for key, value in title_mapping.items():\n",
    "        if key.lower() in title.lower():\n",
    "            return value\n",
    "    return title\n",
    "\n",
    "\n",
    "updated_title = dfdb[\"title\"].apply(map_job_title)\n",
    "dfdb[\"title\"] = updated_title\n",
    "\n",
    "average_salary_by_title = dfdb.groupby(\"title\")['salary'].mean()\n",
    "#df2['salary'] = df2.apply(lambda row: average_salary_by_title[row['title']] if pd.isna(row['salary']) else row['salary'], axis=1)\n",
    "\n",
    "state_mapping_full = {\n",
    "    \"United States\": \"United States\",\n",
    "    \"New York City Metropolitan Area\": \"New York\",\n",
    "    \"Chicago, IL\": \"Illinois\",\n",
    "    \"New York, NY\": \"New York\",\n",
    "    \"Austin, TX\": \"Texas\",\n",
    "    \"Texas, United States\": \"Texas\",\n",
    "    \"Timonium, MD\": \"Maryland\",\n",
    "    \"Dallas, TX\": \"Texas\",\n",
    "    \"Boston, MA\": \"Massachusetts\",\n",
    "    \"Charlotte, NC\": \"North Carolina\",\n",
    "    \"Miami, FL\": \"Florida\",\n",
    "    \"New York, United States\": \"New York\",\n",
    "    \"Franklin, TN\": \"Tennessee\",\n",
    "    \"Tempe, AZ\": \"Arizona\",\n",
    "    \"Illinois, United States\": \"Illinois\",\n",
    "    \"Greensboro--Winston-Salem--High Point Area\": \"North Carolina\",\n",
    "    \"Greater Scranton Area\": \"Pennsylvania\",\n",
    "    \"Tennessee, United States\": \"Tennessee\",\n",
    "    \"Indiana, United States\": \"Indiana\",\n",
    "    \"Denver Metropolitan Area\": \"Colorado\",\n",
    "    \"District of Columbia, United States\": \"District of Columbia\",\n",
    "    \"Conshohocken, PA\": \"Pennsylvania\",\n",
    "    \"Phoenix, AZ\": \"Arizona\",\n",
    "    \"North Carolina, United States\": \"North Carolina\",\n",
    "    \"Greater Sacramento\": \"California\",\n",
    "    \"Richfield, MN\": \"Minnesota\",\n",
    "    \"Morgan Hill, CA\": \"California\",\n",
    "    \"Cincinnati Metropolitan Area\": \"Ohio\",\n",
    "    \"Hartford, CT\": \"Connecticut\",\n",
    "    \"Atlanta Metropolitan Area\": \"Georgia\",\n",
    "    \"Quincy, MA\": \"Massachusetts\",\n",
    "    \"Buffalo-Niagara Falls Area\": \"New York\",\n",
    "    \"San Francisco, CA\": \"California\",\n",
    "    \"Irvine, CA\": \"California\",\n",
    "    \"Houston, TX\": \"Texas\",\n",
    "    \"Omaha, NE\": \"Nebraska\",\n",
    "    \"San Jose, CA\": \"California\",\n",
    "    \"Scottsdale, AZ\": \"Arizona\",\n",
    "    \"San Francisco Bay Area\": \"California\",\n",
    "    \"Manassas, VA\": \"Virginia\"\n",
    "}\n",
    "\n",
    "\n",
    "dfdb['location'] = dfdb['location'].map(state_mapping_full)\n",
    "\n",
    "state_counts = dfdb[\"location\"].value_counts()\n",
    "total_count = state_counts.sum() - state_counts[\"United States\"]\n",
    "ratios = state_counts / total_count\n",
    "replacements = (dfdb[\"location\"].value_counts()[\"United States\"] * ratios).round().astype(int)\n",
    "print(replacements)\n",
    "for i, location in enumerate(dfdb[\"location\"]):\n",
    "    if location == \"United States\":\n",
    "        for key, value in replacements.items():\n",
    "            if value > 0 and key != \"United States\":\n",
    "                dfdb.at[i, \"location\"] = key\n",
    "                replacements[key] -= 1\n",
    "                break\n",
    "\n",
    "\n",
    "dfdb.groupby(\"location\")[\"salary\"].mean()\n",
    "\n",
    "data = {\n",
    "    \"State\": [\"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\",\n",
    "                 \"Florida\", \"Georgia\", \"Illinois\", \"Indiana\", \"Maryland\", \"Massachusetts\",\n",
    "                 \"Minnesota\", \"Nebraska\", \"New York\", \"North Carolina\", \"Ohio\", \n",
    "                 \"Pennsylvania\", \"Tennessee\", \"Texas\"],\n",
    "    \"Av_asalary\": [81431.818182, 70408.450704, 40411.111111, 89375.000000, 117546.511628,\n",
    "               86250.000000, 81888.888889, 86000.000000, 103750.000000, 86363.636364,\n",
    "               82700.000000, 50583.333333, 95000.000000, 72483.673469, 69901.639344,\n",
    "               71000.000000, 86603.829787, 102305.555556, 83276.595745],\n",
    "    \"Number_of_Vac\": [135, 251, 49, 47, 49, 54, 46, 258, 50, 82, 119, 47, 41, 475, 153, 47, 97, 101, 302]\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db7743ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[0;32m      9\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAv_asalary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAv_asalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber_of_Vac\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber_of_Vac\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:105\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[0;32m    101\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:150\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m     )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "merged_df = pd.merge(population_df, income_state_df, on='State', how='left')\n",
    "merged_df = pd.merge(merged_df, result_df, on='State', how='left')\n",
    "merged_df['Population'] = merged_df['Population'].str.replace(',', '').astype(int)\n",
    "merged_df['Av_income'] = merged_df['Av_income'].str.replace(',', '').astype(int)\n",
    "merged_df.dropna(how='any', inplace=True)\n",
    "merged_df.reset_index(drop= True )\n",
    "\n",
    "merged_df.loc['Av_asalary'] = merged_df['Av_asalary'].astype(int)\n",
    "merged_df.loc['Number_of_Vac'] = merged_df['Number_of_Vac'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eae1515f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVacancies/1_mln_Population\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber_of_Vac\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation*1000000\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "merged_df['Vacancies/1_mln_Population'] = ['Number_of_Vac'/'Population*1000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf3c1536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Av_income</th>\n",
       "      <th>Av_asalary</th>\n",
       "      <th>Number_of_Vac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>22610726.0</td>\n",
       "      <td>58390.0</td>\n",
       "      <td>81431.818182</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>12961683.0</td>\n",
       "      <td>77013.0</td>\n",
       "      <td>70408.450704</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>12549689.0</td>\n",
       "      <td>75708.0</td>\n",
       "      <td>40411.111111</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>11785935.0</td>\n",
       "      <td>83340.0</td>\n",
       "      <td>89375.000000</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>10835491.0</td>\n",
       "      <td>96092.0</td>\n",
       "      <td>117546.511628</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>10037261.0</td>\n",
       "      <td>64804.0</td>\n",
       "      <td>86250.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>9290841.0</td>\n",
       "      <td>56588.0</td>\n",
       "      <td>81888.888889</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>7431344.0</td>\n",
       "      <td>67653.0</td>\n",
       "      <td>86000.000000</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>7126489.0</td>\n",
       "      <td>58329.0</td>\n",
       "      <td>103750.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>5877610.0</td>\n",
       "      <td>70236.0</td>\n",
       "      <td>86363.636364</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>5737915.0</td>\n",
       "      <td>84551.0</td>\n",
       "      <td>82700.000000</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>5108468.0</td>\n",
       "      <td>68874.0</td>\n",
       "      <td>50583.333333</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>4053824.0</td>\n",
       "      <td>64263.0</td>\n",
       "      <td>95000.000000</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York</td>\n",
       "      <td>3067732.0</td>\n",
       "      <td>75423.0</td>\n",
       "      <td>72483.673469</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2940546.0</td>\n",
       "      <td>58125.0</td>\n",
       "      <td>69901.639344</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2114371.0</td>\n",
       "      <td>57759.0</td>\n",
       "      <td>71000.000000</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1770071.0</td>\n",
       "      <td>64506.0</td>\n",
       "      <td>86603.829787</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1132812.0</td>\n",
       "      <td>58311.0</td>\n",
       "      <td>102305.555556</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1095962.0</td>\n",
       "      <td>62585.0</td>\n",
       "      <td>83276.595745</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Av_asalary</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           State  Population  Av_income     Av_asalary  \\\n",
       "2                        Arizona  22610726.0    58390.0   81431.818182   \n",
       "4                     California  12961683.0    77013.0   70408.450704   \n",
       "5                       Colorado  12549689.0    75708.0   40411.111111   \n",
       "6                    Connecticut  11785935.0    83340.0   89375.000000   \n",
       "8           District of Columbia  10835491.0    96092.0  117546.511628   \n",
       "9                        Florida  10037261.0    64804.0   86250.000000   \n",
       "10                       Georgia   9290841.0    56588.0   81888.888889   \n",
       "13                      Illinois   7431344.0    67653.0   86000.000000   \n",
       "14                       Indiana   7126489.0    58329.0  103750.000000   \n",
       "20                      Maryland   5877610.0    70236.0   86363.636364   \n",
       "21                 Massachusetts   5737915.0    84551.0   82700.000000   \n",
       "23                     Minnesota   5108468.0    68874.0   50583.333333   \n",
       "27                      Nebraska   4053824.0    64263.0   95000.000000   \n",
       "32                      New York   3067732.0    75423.0   72483.673469   \n",
       "33                North Carolina   2940546.0    58125.0   69901.639344   \n",
       "35                          Ohio   2114371.0    57759.0   71000.000000   \n",
       "38                  Pennsylvania   1770071.0    64506.0   86603.829787   \n",
       "42                     Tennessee   1132812.0    58311.0  102305.555556   \n",
       "43                         Texas   1095962.0    62585.0   83276.595745   \n",
       "Av_asalary                   NaN         NaN        NaN            NaN   \n",
       "\n",
       "            Number_of_Vac  \n",
       "2                   135.0  \n",
       "4                   251.0  \n",
       "5                    49.0  \n",
       "6                    47.0  \n",
       "8                    49.0  \n",
       "9                    54.0  \n",
       "10                   46.0  \n",
       "13                  258.0  \n",
       "14                   50.0  \n",
       "20                   82.0  \n",
       "21                  119.0  \n",
       "23                   47.0  \n",
       "27                   41.0  \n",
       "32                  475.0  \n",
       "33                  153.0  \n",
       "35                   47.0  \n",
       "38                   97.0  \n",
       "42                  101.0  \n",
       "43                  302.0  \n",
       "Av_asalary            NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63884d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b60806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
