{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c10f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd94287e-3f0a-4fe6-b1d2-45a2eb634100",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\zaiid\\\\OneDrive\\\\Desktop\\\\archive_3\\\\linkedin-jobs-usa.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzaiid\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124marchive_3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlinkedin-jobs-usa.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m dfd\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\zaiid\\\\OneDrive\\\\Desktop\\\\archive_3\\\\linkedin-jobs-usa.csv'"
     ]
    }
   ],
   "source": [
    "dfd = pd.read_csv(r\"C:\\Users\\zaiid\\OneDrive\\Desktop\\archive_3\\linkedin-jobs-usa.csv\")\n",
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279ddc2-0cf0-421f-a458-3a5485db68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4ee05-c643-458d-a630-ff2ba6b95fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_values = dfd['salary'].str.split('-', expand=True)\n",
    "lower_salary = salary_values[0].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "upper_salary = salary_values[1].str.replace('[^\\d.]', '', regex=True).astype(float)\n",
    "average = (upper_salary + lower_salary)/2\n",
    "dfd['salary'] = average.round()\n",
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91618daf-367a-40e0-abbf-438c1637b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.salary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a911605-4118-4879-9715-9b51ce2b0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_salary ={55.0 : 55000.0,\n",
    "              70.0 : 70000.0,\n",
    "              50.0 : 50000.0,\n",
    "              32.0 : 32000.0,\n",
    "              60.0 : 60000.0,\n",
    "              30.0 : 30000.0,\n",
    "              23.0 : 45000.0,\n",
    "              45.0 : 45000.0,\n",
    "              42.0 : 42000.0,\n",
    "              5900.0 : 59000.0,\n",
    "              29.0 : 29000.0,\n",
    "              35.0 : 35000.0,\n",
    "              36.0 :36000.0,\n",
    "              40.0 :40000.0,\n",
    "              69.0 :69000.0\n",
    "              }\n",
    "dfd.salary = dfd.salary.replace(dict_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66317b6a-78d0-45e6-bfb5-91c96ce8497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.salary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0076a8-fec8-433d-accf-765411fce2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.title.fillna(\"Junior Data Analyst\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e60763-6be2-4867-bab3-9d2d7080990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6459ab0-5962-4d2b-ae67-741c3362c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa082b50-c467-47f7-8e4c-bee7551ba03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map similar job titles to a standardized title\n",
    "#title_mapping = {\n",
    " #   \"Analyst (Global Data and Analytics)\": \"Global Data and Analytics Analyst\",\n",
    "  #  \"Analyst - Data Visualization\": \"Data Visualization Analyst\",\n",
    "  #  \"Analyst, Data and Analytics\": \"Data and Analytics Analyst\",\n",
    "   # \"Associate Data Analyst\": \"Associate Data Analyst\",\n",
    "    #\"Business Data Analyst\": \"Business Data Analyst\",\n",
    " #   \"Consultant/Data Analyst\": \"Consultant/Data Analyst\",\n",
    " #   \"Data Analyst\": \"Data Analyst\",\n",
    " #   \"Data Analyst (Global Remote)\": \"Global Remote Data Analyst\",\n",
    " #   \"Data Analyst (Hybrid)\": \"Hybrid Data Analyst\",\n",
    " #   \"Data Analyst (Remote)\": \"Remote Data Analyst\",\n",
    " #   \"Data Analyst (SQL)\": \"SQL Data Analyst\",\n",
    "   # \"Data Analyst (SQL, Teraform, Tableau) III - Remote\": \"Remote SQL Data Analyst\",\n",
    "    #\"Data Analyst - (Remote - US)\": \"Remote US Data Analyst\",\n",
    "  #  \"Data Analyst - Energy\": \"Energy Data Analyst\",\n",
    "   # \"Data Analyst - Recent Graduate\": \"Recent Graduate Data Analyst\",\n",
    "  #  \"Data Analyst - Remote\": \"Remote Data Analyst\",\n",
    "  #  \"Data Analyst - Weekly Hybrid Remote/Onsite Schedule\": \"Weekly Hybrid Remote/Onsite Data Analyst\",\n",
    "  #  \"Data Analyst - remote!\": \"Remote Data Analyst\",\n",
    "  #  \"Data Analyst I\": \"Data Analyst I\",\n",
    "  #  \"Data Analyst I (entry level)\": \"Entry Level Data Analyst\",\n",
    "  #  \"Data Analyst III - Remote\": \"Remote Data Analyst III\",\n",
    "  #  \"Data Analyst, Money\": \"Money Data Analyst\",\n",
    "  #  \"Data Analyst/ $100M Valuation/ Hybrid\": \"Hybrid Data Analyst\",\n",
    "  #  \"Data Analyst/Collector\": \"Collector Data Analyst\",\n",
    "  #  \"Data Analytics Analyst\": \"Data Analytics Analyst\",\n",
    "  #  \"Data Visualization Analyst\": \"Data Visualization Analyst\",\n",
    "  #  \"Data analyst\": \"Data Analyst\",\n",
    "  #  \"Entry Level Data Analyst\": \"Entry Level Data Analyst\",\n",
    "   # \"Entry-Level Data Analyst\": \"Entry Level Data Analyst\",\n",
    "    #\"Group Data Analyst\": \"Group Data Analyst\",\n",
    "    #\"Junior Data Analyst\": \"Junior Data Analyst\",\n",
    "  #  \"Junior Data Analyst-Entry Level\": \"Junior Data Analyst\",\n",
    "  #  \"Marketing Data Analyst\": \"Marketing Data Analyst\",\n",
    "  #  \"REMOTE Data Analyst (SQL, Operations)\": \"Remote SQL Data Analyst\",\n",
    "   # \"SQL Data Analyst\": \"SQL Data Analyst\",\n",
    "   # \"Senior Data Analyst\": \"Senior Data Analyst\"\n",
    "#}\n",
    "\n",
    "# Update DataFrame with standardized job titles\n",
    "#df2['title'] = df2['title'].map(title_mapping)\n",
    "# Dictionary to map similar job titles to a standardized title\n",
    "title_mapping = {\n",
    "    \"Data Visualization\": \"Data Visualization\",\n",
    "    \"Junior\": \"Junior Data Analyst\",\n",
    "    \"Data and Analytics\": \"Data and Analytics\",\n",
    "    \"Associate Data Analyst\": \"Associate Data Analyst\",\n",
    "    \"Business Data Analyst\": \"Business Data Analyst\",\n",
    "    \"Consultant\": \"Consultant\",\n",
    "    \"Global Remote\": \"Remote Data Analyst\",\n",
    "    \"Hybrid\": \"Hybrid Data Analyst\",\n",
    "    \"Remote\": \"Remote Data Analyst\",\n",
    "    \"SQL\": \"SQL Data Analyst\",\n",
    "    \"Energy\": \"Energy Data Analyst\",\n",
    "    \"Recent Graduate\": \"Recent Graduate Data Analyst\",\n",
    "    \"Weekly Hybrid Remote/Onsite Schedule\": \"Hybrid Data Analyst\",\n",
    "    \"Collector\": \"Collector Data Analyst\",\n",
    "    \"Data Analytics\": \"Data Analytics Analyst\",\n",
    "    \"Marketing\": \"Marketing Data Analyst\",\n",
    "    \"SQL, Operations\": \"SQL Data Analyst\",\n",
    "    \"Senior\": \"Senior Data Analyst\",\n",
    "    \"Entry Level\": \"Entry Level Data Analyst\",\n",
    "    \"Data Analyst\": \"Data Analyst\"\n",
    "}\n",
    "\n",
    "# Update DataFrame with standardized job titles\n",
    "def map_job_title(title):\n",
    "    for key, value in title_mapping.items():\n",
    "        if key.lower() in title.lower():\n",
    "            return value\n",
    "    return title\n",
    "\n",
    "\n",
    "updated_title = dfd[\"title\"].apply(map_job_title)\n",
    "dfd[\"title\"] = updated_title\n",
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790bffe-2564-4009-b7a3-047230abb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.location.value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1d95f-4208-484e-8de4-983c4518f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salary_by_title = dfd.groupby(\"title\")['salary'].mean()\n",
    "#df2['salary'] = df2.apply(lambda row: average_salary_by_title[row['title']] if pd.isna(row['salary']) else row['salary'], axis=1)\n",
    "average_salary_by_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9c441-7115-48e2-97c4-db60a03a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_mapping_full = {\n",
    "    \"United States\": \"United States\",\n",
    "    \"New York City Metropolitan Area\": \"New York\",\n",
    "    \"Chicago, IL\": \"Illinois\",\n",
    "    \"New York, NY\": \"New York\",\n",
    "    \"Austin, TX\": \"Texas\",\n",
    "    \"Texas, United States\": \"Texas\",\n",
    "    \"Timonium, MD\": \"Maryland\",\n",
    "    \"Dallas, TX\": \"Texas\",\n",
    "    \"Boston, MA\": \"Massachusetts\",\n",
    "    \"Charlotte, NC\": \"North Carolina\",\n",
    "    \"Miami, FL\": \"Florida\",\n",
    "    \"New York, United States\": \"New York\",\n",
    "    \"Franklin, TN\": \"Tennessee\",\n",
    "    \"Tempe, AZ\": \"Arizona\",\n",
    "    \"Illinois, United States\": \"Illinois\",\n",
    "    \"Greensboro--Winston-Salem--High Point Area\": \"North Carolina\",\n",
    "    \"Greater Scranton Area\": \"Pennsylvania\",\n",
    "    \"Tennessee, United States\": \"Tennessee\",\n",
    "    \"Indiana, United States\": \"Indiana\",\n",
    "    \"Denver Metropolitan Area\": \"Colorado\",\n",
    "    \"District of Columbia, United States\": \"District of Columbia\",\n",
    "    \"Conshohocken, PA\": \"Pennsylvania\",\n",
    "    \"Phoenix, AZ\": \"Arizona\",\n",
    "    \"North Carolina, United States\": \"North Carolina\",\n",
    "    \"Greater Sacramento\": \"California\",\n",
    "    \"Richfield, MN\": \"Minnesota\",\n",
    "    \"Morgan Hill, CA\": \"California\",\n",
    "    \"Cincinnati Metropolitan Area\": \"Ohio\",\n",
    "    \"Hartford, CT\": \"Connecticut\",\n",
    "    \"Atlanta Metropolitan Area\": \"Georgia\",\n",
    "    \"Quincy, MA\": \"Massachusetts\",\n",
    "    \"Buffalo-Niagara Falls Area\": \"New York\",\n",
    "    \"San Francisco, CA\": \"California\",\n",
    "    \"Irvine, CA\": \"California\",\n",
    "    \"Houston, TX\": \"Texas\",\n",
    "    \"Omaha, NE\": \"Nebraska\",\n",
    "    \"San Jose, CA\": \"California\",\n",
    "    \"Scottsdale, AZ\": \"Arizona\",\n",
    "    \"San Francisco Bay Area\": \"California\",\n",
    "    \"Manassas, VA\": \"Virginia\"\n",
    "}\n",
    "\n",
    "\n",
    "dfd['location'] = dfd['location'].map(state_mapping_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5908d8-12fd-4f2d-80a0-279f8153164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb28045-d6cf-4cbd-bf78-b551912f1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = dfd[\"location\"].value_counts()\n",
    "total_count = state_counts.sum() - state_counts[\"United States\"]\n",
    "ratios = state_counts / total_count\n",
    "replacements = (dfd[\"location\"].value_counts()[\"United States\"] * ratios).round().astype(int)\n",
    "print(replacements)\n",
    "for i, location in enumerate(dfd[\"location\"]):\n",
    "    if location == \"United States\":\n",
    "        for key, value in replacements.items():\n",
    "            if value > 0 and key != \"United States\":\n",
    "                dfd.at[i, \"location\"] = key\n",
    "                replacements[key] -= 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb8334-e4f3-44bf-bcea-8f1dedfc25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9b3b2-1c76-4081-b2d2-57f6a5d2cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca2ab4-6324-4b60-8e1b-7481b1539a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.groupby(\"location\")[\"salary\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b143c-0dee-405c-8a2f-d4c28d6101e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be436e-f417-4f6e-a148-66376be7f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"location\": [\"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\",\n",
    "                 \"Florida\", \"Georgia\", \"Illinois\", \"Indiana\", \"Maryland\", \"Massachusetts\",\n",
    "                 \"Minnesota\", \"Nebraska\", \"New York\", \"North Carolina\", \"Ohio\", \n",
    "                 \"Pennsylvania\", \"Tennessee\", \"Texas\"],\n",
    "    \"salary\": [81431.818182, 70408.450704, 40411.111111, 89375.000000, 117546.511628,\n",
    "               86250.000000, 81888.888889, 86000.000000, 103750.000000, 86363.636364,\n",
    "               82700.000000, 50583.333333, 95000.000000, 72483.673469, 69901.639344,\n",
    "               71000.000000, 86603.829787, 102305.555556, 83276.595745],\n",
    "    \"count\": [135, 251, 49, 47, 49, 54, 46, 258, 50, 82, 119, 47, 41, 475, 153, 47, 97, 101, 302]\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(data)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490aff9f-41f3-4aba-ad9b-fa1902b1ae30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
